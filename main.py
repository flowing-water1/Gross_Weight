import os
import pandas as pd
import streamlit as st
from weight_calculation import calculate_total_weight
from data_extraction import extract_product_and_quantity
from data_cleaning import clean_product_name, clean_product_specifications
from matching import find_best_match, find_best_match_by_code
from original_data import For_Update_Product_names, For_Update_Product_weights, For_Update_Product_codes, \
    For_Update_Specifications, For_Update_Original_data
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
from st_copy_to_clipboard import st_copy_to_clipboard
import streamlit_toggle as tog
import base64
from io import StringIO
import requests

# Streamlit App Setup
st.set_page_config(layout="wide", initial_sidebar_state='collapsed')
title_col1, title_col2, title_col3 = st.columns([0.6, 1, 0.5])
with title_col2:
    st.title("äº§å“æ•°æ®æå–ä¸é‡é‡è®¡ç®—")

# ä¸Šä¼ å›¾ç‰‡
uploaded_image = st.file_uploader("ä¸Šä¼ äº§å“å›¾ç‰‡", type=["png", "jpg", "jpeg"])

# åˆå§‹åŒ– session_state
if "toggle_status" not in st.session_state:
    st.session_state["toggle_status"] = False


@st.fragment
def toggle_fragment():
    # åŠ¨æ€æ›´æ–° label æ–‡æœ¬
    label_text = "ğŸ”– è¾“å…¥åç§° ğŸ”–" if not st.session_state["toggle_status"] else "ğŸ§¬ è¾“å…¥ç¼–ç  ğŸ§¬"

    # åˆ‡æ¢æ§ä»¶
    toggle_status = tog.st_toggle_switch(
        label=label_text,  # ä½¿ç”¨åŠ¨æ€æ–‡æœ¬
        key="input_toggle",
        default_value=st.session_state["toggle_status"],
        label_after=True,
        inactive_color='#95e1d3',
        active_color="#f38181",
        track_color="#f38181"
    )

    # æ£€æµ‹åˆ‡æ¢çŠ¶æ€å¹¶æ›´æ–°ï¼Œä¸éœ€è¦åˆ·æ–°æ•´ä¸ªé¡µé¢
    if toggle_status != st.session_state["toggle_status"]:
        st.session_state["toggle_status"] = toggle_status
        st.rerun()


# ä¾§è¾¹æ ç®€æ˜“åŠŸèƒ½
with st.sidebar:
    st.header("ç®€æ˜“åŒ¹é…å·¥å…·")

    toggle_fragment()

    if not st.session_state["toggle_status"]:  # False è¡¨ç¤ºè¾“å…¥åç§°

        sidebar_product_name = st.text_input("è¾“å…¥äº§å“åç§°", key="namğŸ§¬e_input")
        sidebar_product_code = st.text_input("è¾“å…¥äº§å“ç¼–ç ", disabled=True, key="code_input")
    else:  # True è¡¨ç¤ºè¾“å…¥ç¼–ç 
        sidebar_product_name = st.text_input("è¾“å…¥äº§å“åç§°", disabled=True, key="name_input")
        sidebar_product_code = st.text_input("è¾“å…¥äº§å“ç¼–ç ", key="code_input")

    sidebar_quantity = st.number_input("è¾“å…¥æ•°é‡", min_value=0, step=1)

    if (sidebar_product_name or sidebar_product_code) and sidebar_quantity > 0:

        # æ¸…æ´—äº§å“åç§°æˆ–ç¼–ç 
        cleaned_name = clean_product_name(sidebar_product_name) if sidebar_product_name else None
        cleaned_code = sidebar_product_code.strip() if sidebar_product_code else None

        # ä»åŒ¹é…æ–‡ä»¶ä¸­è¯»å–äº§å“æ•°æ®
        matching_file_path = 'cleaned_data.xlsx'  # éœ€è¦åœ¨åŒä¸€ç›®å½•ä¸‹æä¾›è¯¥æ–‡ä»¶
        df = pd.read_excel(matching_file_path, sheet_name='å¢ƒå¤–è´¸æ˜“å•†å“åç§°')

        product_names = df['å‹å·'].dropna().astype(str).tolist()
        original_product_names = df['å‹å·'].dropna().astype(str).tolist()  # å‡è®¾è¿™ä¸ªåˆ—è¡¨åŒ…å«åŸå§‹æœªæ¸…æ´—çš„åç§°
        product_weights = df['æ¯›é‡ï¼ˆç®±/æ¡¶ï¼‰'].dropna().astype(float).tolist()
        product_codes = df['äº§å“ç¼–ç (é‡‘è¶äº‘)'].dropna().astype(str).tolist()

        # åŒ¹é…äº§å“
        if cleaned_name:
            match_result = find_best_match(
                cleaned_name,
                product_names,
                product_weights,
                product_codes,
            )
        elif cleaned_code:
            match_result = find_best_match_by_code(
                cleaned_code,
                product_codes,
                product_weights,
                product_names,
                original_product_names,
            )
        best_match = match_result["best_match"]
        all_matches = match_result["all_matches"]

        if best_match["similarity"] < 99:
            # æä¾›å‰ 5 ä¸ªåŒ¹é…é¡¹ä¾›é€‰æ‹©
            options = [
                f"ç¼–å·ï¼š{match['code']} | äº§å“åç§°ï¼š {For_Update_Original_data.loc[For_Update_Original_data['äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰'] == match['code'].strip(), 'äº§å“åç§°'].values[0]} | ç›¸ä¼¼åº¦: {match['similarity']} | æ¯›é‡: {match['weight']}"
                for match in all_matches
            ]

            user_selection = st.selectbox(
                "é€‰æ‹©æœ€ä½³åŒ¹é…é¡¹",
                options,
                index=0,
                key="sidebar_selection"
            )

            # ä½¿ç”¨äº§å“ç¼–å·åŒ¹é…
            original_product_name = user_selection.split("|")[1].strip().replace("äº§å“åç§°ï¼š", "").strip()  # è·å–æœªæ¸…æ´—çš„äº§å“åç§°
            selected_product_code = user_selection.split("|")[0].strip().replace("ç¼–å·ï¼š", "").strip()
            selected_match = next(
                (match for match in all_matches if match["code"].strip() == selected_product_code), None
            )

            product_spec = For_Update_Original_data.loc[
                For_Update_Original_data['äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰'] == selected_match['code'].strip(), 'äº§å“è§„æ ¼'].values[0]
            cleaned_spec = clean_product_specifications(product_spec)  # æ¸…æ´—è§„æ ¼

            if selected_match is None:
                st.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒ¹é…é¡¹ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–é‡æ–°é€‰æ‹©ã€‚")
            else:
                st.info(
                    f"é€‰æ‹©çš„äº§å“åç§°: {original_product_name}  \né€‰æ‹©çš„äº§å“ç¼–ç : {selected_match['code']}  \näº§å“è§„æ ¼ï¼š{product_spec}  \næ¯›é‡: {selected_match['weight']} KG")
                total_weight = calculate_total_weight(
                    product_names=[original_product_name],  # ä½¿ç”¨åŸå§‹äº§å“åç§°
                    quantities=[sidebar_quantity],
                    cleaned_product_specifications_names=[cleaned_spec],  # ä¼ å…¥æ¸…æ´—åçš„è§„æ ¼
                    matched_product_weights=[selected_match['weight']],
                    matched_product_codes=[selected_match['code']]
                )
                st.success(f"æ€»æ¯›é‡: {total_weight:.2f} KG")
        else:
            # ä½¿ç”¨æœªæ¸…æ´—çš„äº§å“åç§°æ¥å±•ç¤ºæœ€ä½³åŒ¹é…
            original_best_product_name = For_Update_Original_data.loc[
                For_Update_Original_data['äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰'] == best_match['code'].strip(), 'äº§å“åç§°'].values[0]
            product_spec = For_Update_Original_data.loc[
                For_Update_Original_data['äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰'] == best_match['code'].strip(), 'äº§å“è§„æ ¼'].values[0]
            cleaned_spec = clean_product_specifications(product_spec)  # æ¸…æ´—è§„æ ¼

            # è½¬ä¹‰ï¼Œé¿å…æ–‡å­—å˜æˆæ–œä½“
            original_best_product_name_escaped = original_best_product_name.replace("*", "\\*")
            product_spec_escaped = product_spec.replace("*", "\\*")
            st.info(
                f"æœ€ä½³åŒ¹é…é¡¹åç§°: {original_best_product_name_escaped}  \næœ€ä½³åŒ¹é…é¡¹ç¼–ç : {best_match['code']}  \näº§å“è§„æ ¼ï¼š{product_spec_escaped}  \næ¯›é‡: {best_match['weight']} KG")

            total_weight = calculate_total_weight(
                product_names=[original_best_product_name],  # ä½¿ç”¨åŸå§‹äº§å“åç§°
                quantities=[sidebar_quantity],
                cleaned_product_specifications_names=[cleaned_spec],  # ä¼ å…¥æ¸…æ´—åçš„è§„æ ¼
                matched_product_weights=[best_match['weight']],
                matched_product_codes=[best_match['code']]
            )
            st.success(f"æ€»æ¯›é‡: {total_weight:.2f} KG")

if uploaded_image:
    # åˆå§‹åŒ– session_state å˜é‡
    if 'previous_uploaded_file_name' not in st.session_state:
        st.session_state['previous_uploaded_file_name'] = uploaded_image.name

    # å¦‚æœä¸Šä¼ äº†æ–°çš„æ–‡ä»¶ï¼Œä¸ä¹‹å‰çš„æ–‡ä»¶ä¸åŒï¼Œåˆ™æ¸…ç©º session_state ä¸­é™¤ `previous_uploaded_file_name` ä»¥å¤–çš„æ•°æ®
    if st.session_state['previous_uploaded_file_name'] != uploaded_image.name:
        # ä¿ç•™åŸå§‹çš„æ–‡ä»¶åä»¥é¿å…è¢«æ¸…é™¤
        previous_uploaded_file_name = st.session_state['previous_uploaded_file_name']
        # æ¸…ç©ºæ‰€æœ‰ session_stateï¼Œé‡æ–°è®¾ç½® `previous_uploaded_file_name`
        st.session_state.clear()
        st.session_state['previous_uploaded_file_name'] = previous_uploaded_file_name
        st.session_state['previous_uploaded_file_name'] = uploaded_image.name

    if 'ocr_result_df' not in st.session_state:
        st.toast(f"ä½ ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶æ˜¯: {uploaded_image.name}")
        st.divider()
        st.info("æ–‡ä»¶é¢„è§ˆï¼š")
        st.image(uploaded_image, caption='ä¸Šä¼ çš„å›¾ç‰‡', use_column_width=True)

        # ä½¿ç”¨ NamedTemporaryFile ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        original_file_name = os.path.splitext(uploaded_image.name)[0]
        standardized_filename = f"{original_file_name}_uploaded.png"
        temp_file_path = os.path.join(".", standardized_filename)
        with open(temp_file_path, "wb") as temp_file:
            temp_file.write(uploaded_image.read())

        # OCR å¤„ç†éƒ¨åˆ†ï¼ˆä½¿ç”¨æœåŠ¡ç«¯ API æ›¿æ¢æœ¬åœ°æ¨¡å‹ï¼‰
        st.toast("æ­£åœ¨è¿›è¡Œè¡¨æ ¼è¯†åˆ«...")

        try:
            # å¯¹æœ¬åœ°å›¾åƒè¿›è¡Œ Base64 ç¼–ç 
            with open(temp_file_path, "rb") as file:
                image_bytes = file.read()
                image_data = base64.b64encode(image_bytes).decode("ascii")

            # è°ƒç”¨ API
            API_URL = "https://api123.1127107.xyz/table-recognition"
            payload = {"image": image_data}
            response = requests.post(API_URL, json=payload, timeout=10)

            if response.status_code == 200:
                result = response.json().get("result", {})

                if not result:
                    st.error("API è¿”å›çš„æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚")

                # ä¿å­˜ OCR å’Œå¸ƒå±€å›¾åƒ
                result_dir = os.path.join(os.path.dirname(temp_file_path), "out")
                os.makedirs(result_dir, exist_ok=True)
                base_filename = os.path.splitext(os.path.basename(temp_file_path))[0]

                ocr_image_path = os.path.join(result_dir, f"{base_filename}_ocr.jpg")
                layout_image_path = os.path.join(result_dir, f"{base_filename}_layout.jpg")
                with open(ocr_image_path, "wb") as file:
                    file.write(base64.b64decode(result.get("ocrImage", "")))
                with open(layout_image_path, "wb") as file:
                    file.write(base64.b64decode(result.get("layoutImage", "")))

                # æå–è¡¨æ ¼æ•°æ®å¹¶ä¿å­˜ä¸º Excel
                tables = result.get("tables", [])
                xlsx_file_path = os.path.join(result_dir, f"{base_filename}.xlsx")
                if tables:
                    with pd.ExcelWriter(xlsx_file_path) as writer:
                        for idx, table in enumerate(tables):
                            html_content = table.get("html", "")
                            dfs = pd.read_html(StringIO(html_content))
                            if dfs:
                                df = dfs[0]
                                sheet_name = "Sheet"
                                # æ‰“å°è¡¨æ ¼æ•°æ®åŠç›®æ ‡æ–‡ä»¶è·¯å¾„
                                df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)
                    # æ›´æ–° session_state
                    ocr_result_df = pd.read_excel(xlsx_file_path, header=None)
                    ocr_result_df.columns = ["äº§å“åç§°", "äº§å“è§„æ ¼", "æ•°é‡"]
                    st.session_state['ocr_result_df'] = ocr_result_df
                    st.session_state['image_files'] = [layout_image_path, ocr_image_path]
                    st.session_state['xlsx_file_path'] = xlsx_file_path
                    ocr_result_original_df = ocr_result_df.copy()
                    st.session_state['ocr_result_original_df'] = ocr_result_original_df
                else:
                    st.warning("OCR è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
            elif response.status_code == 502:
                st.error("æ— æ³•è¿æ¥åˆ°æœ¬åœ°æœåŠ¡ã€‚è¯·ç¡®ä¿æœ¬åœ°æœåŠ¡å·²å¯åŠ¨ï¼Œå¹¶ä¸”å¯é€šè¿‡å†…ç½‘ç©¿é€è®¿é—®ã€‚")

            else:
                st.error(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                with st.expander("è¯¦ç»†æŠ¥é”™ä¿¡æ¯"):
                    st.error(f"{response.text}")

        except Exception as e:
            # æ•è·è¯·æ±‚å¼‚å¸¸å¹¶æç¤ºæœåŠ¡ç«¯æœªå¯åŠ¨
            st.error("æ— æ³•è¿æ¥åˆ°æœåŠ¡ç«¯ã€‚è¯·ç¡®ä¿æœåŠ¡ç«¯å·²å¯åŠ¨å¹¶ä¸”å¯ä»¥è®¿é—®ã€‚")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š{str(e)}")

    # ä» session_state ä¸­è¯»å– OCR ç»“æœ
    if 'ocr_result_df' in st.session_state:
        st.image(uploaded_image, caption='ä¸Šä¼ çš„å›¾ç‰‡', use_column_width=True)
        ocr_result_df = st.session_state['ocr_result_df']
        image_files = st.session_state.get('image_files', [])
        xlsx_file_path = st.session_state['xlsx_file_path']
        ocr_result_original_df = st.session_state['ocr_result_original_df']

        # å±•ç¤ºè¯†åˆ«çš„å›¾ç‰‡
        expander = st.expander("OCR è¯†åˆ«çš„å›¾ç‰‡ç»“æœï¼š")
        for image_file in image_files:
            if os.path.exists(image_file):
                expander.image(image_file, caption=f"è¯†åˆ«ç»“æœ: {os.path.basename(image_file)}", use_column_width=True)

        # ä» session_state ä¸­è¯»å– OCR ç»“æœ
        markdown_col1, markdown_col2, markdown_col3 = st.columns([1.5, 1, 1])
        with markdown_col2:
            st.markdown(f"""
            ### OCR è¯†åˆ«ç»“æœ
            **æ–‡ä»¶å:** `{uploaded_image.name}`  
            """, unsafe_allow_html=True)

        dataframe_col1, dataframe_col2 = st.columns([0.5, 1])
        with dataframe_col2:
            st.dataframe(ocr_result_df)
        # æå–æ•°æ®
        original_product_names, specifications, quantities = extract_product_and_quantity(xlsx_file_path)

        # æ¸…æ´—æ•°æ®
        cleaned_product_names = [clean_product_name(name) for name in original_product_names]
        cleaned_product_specifications_names = [clean_product_specifications(spec) for spec in specifications]

        # è¯»å–åŒ¹é…äº§å“çš„Excelæ–‡ä»¶
        matching_file_path = 'cleaned_data.xlsx'  # éœ€è¦åœ¨åŒä¸€ç›®å½•ä¸‹æä¾›è¯¥æ–‡ä»¶
        df = pd.read_excel(matching_file_path, sheet_name='å¢ƒå¤–è´¸æ˜“å•†å“åç§°')

        product_names = df['å‹å·'].dropna().astype(str).tolist()
        product_weights = df['æ¯›é‡ï¼ˆç®±/æ¡¶ï¼‰'].dropna().astype(float).tolist()
        product_codes = df['äº§å“ç¼–ç (é‡‘è¶äº‘)'].dropna().astype(str).tolist()

        # åŒ¹é…äº§å“
        matched_product_names = []
        matched_product_weights = []
        matched_product_codes = []

        # ä¸´æ—¶å­˜å‚¨ç”¨æˆ·é€‰æ‹©çš„ç»“æœ
        user_selected_products = {}

        for idx, cleaned_name in enumerate(cleaned_product_names):

            filtered_indices = ocr_result_original_df.index[
                ocr_result_original_df["äº§å“åç§°"] == original_product_names[idx]].tolist()

            if len(filtered_indices) == 0:
                st.warning(f"æ‰¾ä¸åˆ°ä¸äº§å“åç§° '{original_product_names[idx]}' ç›¸åŒ¹é…çš„è¡Œï¼Œè¯·æ£€æŸ¥æ•°æ®ã€‚")
                continue
            else:
                original_row_index = filtered_indices[0]

            match_result = find_best_match(
                cleaned_name,
                product_names,
                product_weights,
                product_codes,
            )

            best_match = match_result["best_match"]
            all_matches = match_result["all_matches"]

            if best_match["similarity"] < 99:
                # æŸ¥æ‰¾ cleaned_name å¯¹åº”çš„åŸå§‹äº§å“åç§°
                original_name = For_Update_Original_data.loc[
                    For_Update_Original_data["äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰"] == best_match["code"], "äº§å“åç§°"].values[0]

                st.warning(
                    f"â†“&emsp; è¡¨æ ¼è¡Œå·ä¸º{original_row_index}è¡Œï¼š äº§å“ '{original_name}' çš„æœ€ä½³åŒ¹é…é¡¹ç›¸ä¼¼åº¦ä¸º {best_match['similarity']}ï¼Œéœ€è¦æ‰‹åŠ¨é€‰æ‹©åŒ¹é…é¡¹&emsp;â†“")

                # æä¾›å‰ 5 ä¸ªåŒ¹é…é¡¹ä¾›é€‰æ‹©
                options = [
                    f"ç¼–å·ï¼š{match['code']} | äº§å“åç§°ï¼š {For_Update_Original_data.loc[For_Update_Original_data['äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰'] == match['code'].strip(), 'äº§å“åç§°'].values[0]} | ç›¸ä¼¼åº¦: {match['similarity']} | æ¯›é‡: {match['weight']} ".replace(
                        " | ", "\u00A0\u00A0\u00A0|\u00A0\u00A0\u00A0")
                    for match in all_matches
                ]

                # é»˜è®¤å€¼ä¸ºç¬¬ä¸€ä¸ªé€‰é¡¹
                default_option = options[0]

                user_selection = st.selectbox(
                    " ",
                    options,
                    index=0,
                    key=f"selection_{idx}",
                    label_visibility="collapsed"
                )
                # ä½¿ç”¨æ–°çš„åˆ†éš”ç¬¦æ¥æ‹†åˆ†é€‰é¡¹å­—ç¬¦ä¸²
                split_separator = "\u00A0\u00A0\u00A0|\u00A0\u00A0\u00A0"
                selected_product_code = user_selection.split(split_separator)[0].strip()  # äº§å“ç¼–å·åœ¨é€‰é¡¹çš„æœ€å‰é¢

                # å¦‚æœå‰ç¼€æ˜¯ "ç¼–å·ï¼š"ï¼ˆæ³¨æ„è¿™é‡Œçš„å…¨è§’ç¬¦å·ï¼‰
                if selected_product_code.startswith("ç¼–å·ï¼š"):
                    selected_product_code = selected_product_code[len("ç¼–å·ï¼š"):].strip()

                # ä½¿ç”¨äº§å“ç¼–å·åŒ¹é…è€Œä¸æ˜¯åç§°åŒ¹é…
                selected_match = next(
                    (match for match in all_matches if match["code"].strip() == selected_product_code.strip()), None)

                if selected_match is None:
                    st.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„åŒ¹é…é¡¹ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–é‡æ–°é€‰æ‹©ã€‚")
                    # ä¸åŒ¹é…ï¼Œè§£å†³è¿™é‡Œçš„é—®é¢˜ï¼Œå¤§æ¦‚ç‡æ˜¯å› ä¸ºæ ¼å¼ä¸åŒï¼Œæ‰€ä»¥æœç´¢ä¸åˆ°ã€‚
                else:
                    # æ›´æ–°åŒ¹é…ç»“æœ
                    matched_product_names.append(selected_match["name"])
                    matched_product_weights.append(selected_match["weight"])
                    matched_product_codes.append(selected_match["code"])

                    # å­˜å‚¨ç”¨æˆ·é€‰æ‹©ç»“æœ
                    user_selected_products[cleaned_name] = selected_match
            else:
                # å¦‚æœç›¸ä¼¼åº¦ >= 99ï¼Œç›´æ¥ä½¿ç”¨æœ€ä½³åŒ¹é…
                matched_product_names.append(best_match["name"])
                matched_product_weights.append(best_match["weight"])
                matched_product_codes.append(best_match["code"])

        # å½“ä½ ä½¿ç”¨ ocr_result_df.insert() æ–¹æ³•æ’å…¥ä¸€ä¸ªæ–°åˆ—æ—¶ï¼Œå¦‚æœè¿™ä¸ªåˆ—å·²ç»å­˜åœ¨äº ocr_result_df ä¸­ï¼Œä¼šæŠ›å‡ºä¸€ä¸ª ValueError é”™è¯¯ï¼Œå› ä¸º insert()
        # æ–¹æ³•è¦æ±‚æ’å…¥çš„åˆ—æ˜¯æ–°çš„ä¸”ä¸å­˜åœ¨çš„ã€‚

        # åœ¨é¦–æ¬¡è¿è¡Œè„šæœ¬æ—¶æ’å…¥åˆ—æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æ˜¯å½“ç”¨æˆ·è¿›è¡Œäº¤äº’ï¼Œé¡µé¢é‡æ–°åŠ è½½æ—¶ï¼Œä»£ç ä¼šå†æ¬¡å°è¯•æ’å…¥è¿™äº›åˆ—ï¼Œè€Œæ­¤æ—¶è¿™äº›åˆ—å·²ç»å­˜åœ¨ï¼Œè¿™å°±ä¼šå¯¼è‡´é”™è¯¯æˆ–è€…äº§ç”Ÿé¢„æœŸå¤–çš„è¡Œä¸ºã€‚
        if "äº§å“ç¼–å·(é‡‘è¶äº‘)" in ocr_result_df.columns:
            ocr_result_df["äº§å“ç¼–å·(é‡‘è¶äº‘)"] = matched_product_codes
        else:
            ocr_result_df.insert(0, "äº§å“ç¼–å·(é‡‘è¶äº‘)", matched_product_codes)

        ocr_result_df["æ¯›é‡"] = matched_product_weights

        # æ›´æ–° ocr_result_df è¡¨æ ¼
        for idx, row in ocr_result_df.iterrows():
            user_input_id = row["äº§å“ç¼–å·(é‡‘è¶äº‘)"]  # è·å–äº§å“ç¼–å·
            if user_input_id in For_Update_Original_data["äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰"].values:
                # æŸ¥æ‰¾ `For_Update_Original_data` ä¸­åŒ¹é…çš„è¡Œ
                correct_row = \
                    For_Update_Original_data[For_Update_Original_data["äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰"] == user_input_id].iloc[0]
                # æ›´æ–° "äº§å“åç§°"ã€"äº§å“è§„æ ¼" å’Œ "æ¯›é‡" åˆ—
                ocr_result_df.at[idx, "äº§å“åç§°"] = correct_row["äº§å“åç§°"]
                ocr_result_df.at[idx, "äº§å“è§„æ ¼"] = correct_row["äº§å“è§„æ ¼"]
                ocr_result_df.at[idx, "æ¯›é‡"] = correct_row["æ¯›é‡ï¼ˆç®±/æ¡¶ï¼‰"]

        # é…ç½® AgGrid é€‰é¡¹
        gb = GridOptionsBuilder.from_dataframe(ocr_result_df)
        gb.configure_grid_options(domLayout='autoHeight')

        gb.configure_column("äº§å“ç¼–å·(é‡‘è¶äº‘)", editable=True)  # ä½¿äº§å“ç¼–å·å¯ç¼–è¾‘
        gb.configure_column("æ¯›é‡",editable = True)
        gb.configure_column("äº§å“è§„æ ¼",editable =True)
        gb.configure_column("æ•°é‡", editable=True)  # ä½¿æ•°é‡åˆ—å¯ç¼–è¾‘

        gb.configure_default_column(min_column_width=100)
        grid_options = gb.build()

        col1, col2 = st.columns(2)

        with col1:
            # æ˜¾ç¤º AgGrid è¡¨æ ¼å¹¶æ•è·ç”¨æˆ·ä¿®æ”¹
            modify_table_markdown_col1, modify_table_markdown_col2, modify_table_markdown_col3 = st.columns(
                [0.75, 1, 0.5])
            with modify_table_markdown_col2:
                st.markdown(f"""
                            ### ä¿®æ”¹çš„è¡¨æ ¼
                            """, unsafe_allow_html=True)
            response = AgGrid(
                ocr_result_df,
                gridOptions=grid_options,
                editable=True,
                update_mode=GridUpdateMode.MODEL_CHANGED,
                theme="alpine",
                fit_columns_on_grid_load=True
            )

            # è·å–ç”¨æˆ·ä¿®æ”¹åçš„æ•°æ®
            edited_df = pd.DataFrame(response['data'])

            # å°†ä¿®æ”¹åçš„æ•°æ®ä¿å­˜åˆ° session_state ä¸­ï¼Œä»¥ä¾¿åœ¨é¡µé¢åˆ·æ–°æ—¶ä¿ç•™
            st.session_state['edited_ocr_result_df'] = edited_df

        # ä½¿ç”¨æ–°çš„å˜é‡å `updated_ocr_df` ä¿å­˜ä¿®æ”¹åçš„æ•°æ®
        if 'edited_ocr_result_df' in st.session_state:
            updated_ocr_df = st.session_state['edited_ocr_result_df']
        else:
            updated_ocr_df = edited_df

        # å®æ—¶æ£€æµ‹å’Œéƒ¨åˆ†åˆ—æ›¿æ¢
        for index, row in edited_df.iterrows():
            user_input_id = row["äº§å“ç¼–å·(é‡‘è¶äº‘)"]  # åªæ£€æµ‹â€œäº§å“ç¼–å·â€åˆ—
            if user_input_id in For_Update_Original_data["äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰"].values:
                # æŸ¥æ‰¾åœ¨ cleaned_data ä¸­åŒ¹é…çš„è¡Œ
                correct_row = \
                    For_Update_Original_data[For_Update_Original_data["äº§å“ç¼–å·ï¼ˆé‡‘è¶äº‘ï¼‰"] == user_input_id].iloc[0]
                # æ›´æ–° "äº§å“åç§°" å’Œ "äº§å“è§„æ ¼" åˆ—
                updated_ocr_df.at[index, "äº§å“åç§°"] = correct_row["äº§å“åç§°"]
                updated_ocr_df.at[index, "äº§å“è§„æ ¼"] = correct_row["äº§å“è§„æ ¼"]
                updated_ocr_df.at[index, "æ¯›é‡"] = correct_row["æ¯›é‡ï¼ˆç®±/æ¡¶ï¼‰"]

        # æ˜¾ç¤ºæ›´æ–°åçš„ AgGrid è¡¨æ ¼
        with col2:
            determine_table_markdown_col1, determine_table_markdown_col2, determine_table_markdown_col3 = st.columns(
                [0.75, 1, 0.5])
            with determine_table_markdown_col2:
                st.markdown(f"""
                            ### ç¡®å®šçš„è¡¨æ ¼
                            """, unsafe_allow_html=True)
            # st.write("æ›´æ–°åçš„ OCR è¯†åˆ«ç»“æœï¼š")
            st.dataframe(updated_ocr_df)

    if st.button("ç¡®å®š"):
        # æ£€æŸ¥ç¼–è¾‘åçš„ DataFrame æ˜¯å¦å­˜åœ¨
        if 'updated_ocr_df' in locals():
            # æå–æ›´æ–°åçš„æ•°æ®
            updated_product_names = updated_ocr_df["äº§å“åç§°"].tolist()
            updated_quantities = updated_ocr_df["æ•°é‡"].tolist()
            updated_specifications = updated_ocr_df["äº§å“è§„æ ¼"].tolist()

            # æ¸…æ´—äº§å“è§„æ ¼æ•°æ®
            cleaned_updated_specifications_names = [clean_product_specifications(spec) for spec in
                                                    updated_specifications]

            # æå–æ¯›é‡å’Œäº§å“ç¼–å·
            updated_weights = updated_ocr_df["æ¯›é‡"].tolist()
            updated_codes = updated_ocr_df["äº§å“ç¼–å·(é‡‘è¶äº‘)"].tolist()

            # ä½¿ç”¨æ›´æ–°åçš„æ•°æ®è¿›è¡Œè®¡ç®—
            total_weight = calculate_total_weight(
                updated_product_names,
                updated_quantities,
                cleaned_updated_specifications_names,
                updated_weights,
                updated_codes
            )

            # è¾“å‡ºæ€»æ¯›é‡
            st.success(f"è®¡ç®—å®Œæˆï¼æ€»æ¯›é‡: {total_weight:.2f} KG")
            st.divider()

        else:
            st.warning("è¯·å…ˆç¼–è¾‘æ•°æ®å†è¿›è¡Œè®¡ç®—ï¼")
    # å°† DataFrame è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œä»¥ä¾¿åœ¨æ–‡æœ¬åŒºåŸŸä¸­æ˜¾ç¤º
    if 'edited_df' in locals():
        copy_text = edited_df.to_csv(index=False, sep='\t')  # ä½¿ç”¨ tab ä½œä¸ºåˆ†éš”ç¬¦ï¼Œæ›´ä¾¿äºå¤åˆ¶åˆ°è¡¨æ ¼å·¥å…·å¦‚ Excel

        text_area = st.text_area(" ", copy_text, height=200, key="text_area")
        st.divider()
        st_copy_to_clipboard(copy_text)
